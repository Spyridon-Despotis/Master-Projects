{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c800618-64b8-4a8c-9f2d-fa04e93c34ed",
   "metadata": {},
   "source": [
    ">\n",
    "> <a class=\"anchor\" id=\"welcome\"></a> \n",
    "<img src=\"https://i.ibb.co/C9QvSmC/task3.png\" alt=\"Drawing\"  style=\"width: 600px;\"/><br />\n",
    "> <b> <span style=\"font-size: 400%\"> <span style='font-family:Helvetica'> Bookstore Dataset</b>\n",
    ">  <br />\n",
    "> <img src=\"https://i.pinimg.com/originals/4c/79/70/4c7970c030c4b8a8322171dd6a498cb0.gif\" alt=\"Drawing\" style=\"width: 396px;\"/> <br />\n",
    "> <br />\n",
    "> <span style='font-family:Verdana '> Msc in Business Analytics @ AEUB  <br />\n",
    ">  <span style='font-family:Verdana '> Big Data Systems and Architectures - PT  <br />\n",
    ">  <span style='font-family:Verdana '> Professor: Thanasis Vergoulis <br />\n",
    ">  <span style='font-family:Verdana '> Student: Despotis Spyridon  <br />\n",
    ">  <span style='font-family:Verdana '> Student ID: P2822111 <br />\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01dd09-549b-4c52-bdbd-6e53a5708f1a",
   "metadata": {},
   "source": [
    "> <img src=\"https://i.ibb.co/0rTP5XM/table-of-contents.png\" alt=\"Drawing\" style=\"width: 480px;\"/> <br />\n",
    "> * [Task1](#question1) <br />\n",
    "> * [Task2](#question2) <br />\n",
    "> * [Task3](#question3) <br />\n",
    "> * [Task4](#question4) <br />\n",
    "> * [Conclusions for all projects (bonus)](#question5) <br />\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e395b16-c6a1-4947-a7fa-6aa880fcbc64",
   "metadata": {},
   "source": [
    "> <b> <span style=\"font-size: 200%\"> <span style='font-family:Helvetica'>Lets Start our Analysis!</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96587e94-7953-4339-8e5a-9492530e7c32",
   "metadata": {},
   "source": [
    "* Importing the Libraries and creating the spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5483cd67-fcbf-4f54-9864-7bb841eb2baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.ml.evaluation\n",
    "from pyspark.ml.feature import IndexToString, MinMaxScaler, StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "spark = SparkSession.builder.appName(\"books_5000\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0d439b-5b0d-4103-9fb0-2ec51cf152e1",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"question1\"></a> \n",
    "</b>\n",
    "<b> <span style=\"font-size: 200%\"> <span style='font-family:Helvetica'>Task 1 \"Preparing the feature vectors\"</b> \n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5899322f-1c0c-49b1-96f6-5c06b5361a4d",
   "metadata": {},
   "source": [
    "* Reading the books_5000.json using spark json read function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4e7181b-a0b2-48fc-a491-403caa233bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = spark.read.json(\"books_5000.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737ca086-1eaa-4892-900b-17c6244932e6",
   "metadata": {},
   "source": [
    "* Creating new dataframe by slecting the appropriate columns from books dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "803b3396-551b-475b-a8a5-ae95c83f6da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = books.select(col(\"average_rating\"),col(\"language_code\"),col(\"num_pages\"),col(\"ratings_count\"),col(\"publication_year\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934cbe6f-1ed8-4821-a69d-aefed9f5217d",
   "metadata": {},
   "source": [
    "* Encode string columns \"language_code\", \"publication_yearIndex\" to new column with indexes\n",
    "* Then we drop the unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3f6e1be-da5d-49d2-a621-720000a18a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-------------+------------------+---------------------+\n",
      "|average_rating|num_pages|ratings_count|language_codeIndex|publication_yearIndex|\n",
      "+--------------+---------+-------------+------------------+---------------------+\n",
      "|          4.12|         |            1|               0.0|                  0.0|\n",
      "|          3.94|         |           16|               3.0|                  2.0|\n",
      "|          4.28|      146|           51|               1.0|                  5.0|\n",
      "|          4.05|         |            6|               1.0|                  0.0|\n",
      "|          4.06|      272|           51|               6.0|                 20.0|\n",
      "|          3.44|      206|           46|               0.0|                 12.0|\n",
      "|          4.15|      224|           39|               1.0|                  2.0|\n",
      "|          3.16|      160|           38|               0.0|                  2.0|\n",
      "|          3.51|      160|           44|               0.0|                  2.0|\n",
      "|          4.00|      144|           32|               0.0|                  2.0|\n",
      "|          4.41|      212|          133|              20.0|                  3.0|\n",
      "|          3.16|      144|          114|               1.0|                  6.0|\n",
      "|          4.41|      200|          149|               1.0|                  5.0|\n",
      "|          4.39|      230|          152|               0.0|                  5.0|\n",
      "|          1.86|         |           64|               0.0|                  0.0|\n",
      "|          4.31|      157|          174|               5.0|                  4.0|\n",
      "|          4.43|      224|           30|               2.0|                 11.0|\n",
      "|          4.38|      176|            2|              26.0|                  6.0|\n",
      "|          3.80|      192|           86|               0.0|                 11.0|\n",
      "|          4.46|      192|            8|               1.0|                  0.0|\n",
      "+--------------+---------+-------------+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = StringIndexer(inputCol='language_code', outputCol='language_codeIndex').fit(df1).transform(df1)\n",
    "df1 = StringIndexer(inputCol='publication_year', outputCol='publication_yearIndex').fit(df1).transform(df1)\n",
    "df3 = df1.drop(\"language_code\",\"publication_year\")\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd9dca3-b535-4697-8b1a-e7517b350c87",
   "metadata": {},
   "source": [
    "* Then we check for the data types of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97e5e32c-8bf6-4685-bdda-28e00d9422cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('average_rating', 'string'),\n",
       " ('num_pages', 'string'),\n",
       " ('ratings_count', 'string'),\n",
       " ('language_codeIndex', 'double'),\n",
       " ('publication_yearIndex', 'double')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4583e37-ff57-4c70-99c5-5e33f297076f",
   "metadata": {},
   "source": [
    "* Then we proceed by converting each column to the appropriate data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc0e8324-5e82-4b17-a7ed-71539a36d827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-------------+------------------+---------------------+\n",
      "|average_rating|num_pages|ratings_count|language_codeIndex|publication_yearIndex|\n",
      "+--------------+---------+-------------+------------------+---------------------+\n",
      "|          4.12|     null|            1|               0.0|                  0.0|\n",
      "|          3.94|     null|           16|               3.0|                  2.0|\n",
      "|          4.28|      146|           51|               1.0|                  5.0|\n",
      "|          4.05|     null|            6|               1.0|                  0.0|\n",
      "|          4.06|      272|           51|               6.0|                 20.0|\n",
      "|          3.44|      206|           46|               0.0|                 12.0|\n",
      "|          4.15|      224|           39|               1.0|                  2.0|\n",
      "|          3.16|      160|           38|               0.0|                  2.0|\n",
      "|          3.51|      160|           44|               0.0|                  2.0|\n",
      "|           4.0|      144|           32|               0.0|                  2.0|\n",
      "|          4.41|      212|          133|              20.0|                  3.0|\n",
      "|          3.16|      144|          114|               1.0|                  6.0|\n",
      "|          4.41|      200|          149|               1.0|                  5.0|\n",
      "|          4.39|      230|          152|               0.0|                  5.0|\n",
      "|          1.86|     null|           64|               0.0|                  0.0|\n",
      "|          4.31|      157|          174|               5.0|                  4.0|\n",
      "|          4.43|      224|           30|               2.0|                 11.0|\n",
      "|          4.38|      176|            2|              26.0|                  6.0|\n",
      "|           3.8|      192|           86|               0.0|                 11.0|\n",
      "|          4.46|      192|            8|               1.0|                  0.0|\n",
      "+--------------+---------+-------------+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df3.withColumn(\"num_pages\", df3[\"num_pages\"].cast('int'))\n",
    "df3 = df3.withColumn(\"language_codeIndex\", df3[\"language_codeIndex\"].cast('double'))\n",
    "df3 = df3.withColumn(\"publication_yearIndex\", df3[\"publication_yearIndex\"].cast('double'))\n",
    "df3 = df3.withColumn(\"ratings_count\", df3[\"ratings_count\"].cast('int'))\n",
    "df3 = df3.withColumn(\"average_rating\", df3[\"average_rating\"].cast('double'))\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0534d59-f5f0-4fbb-b940-9fe36b2ad93a",
   "metadata": {},
   "source": [
    "* Next we proceed by looking for missing values in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f0b051a-3574-4972-860c-405cf7e1015a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-------------+------------------+---------------------+\n",
      "|average_rating|num_pages|ratings_count|language_codeIndex|publication_yearIndex|\n",
      "+--------------+---------+-------------+------------------+---------------------+\n",
      "|             0|     1382|            0|                 0|                    0|\n",
      "+--------------+---------+-------------+------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "df3.select([count(when(isnull(c), c)).alias(c) for c in df3.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c7e18-a835-4db7-9e47-fec720819d54",
   "metadata": {},
   "source": [
    "* In order to proceed our analysis we drop the empty values\n",
    "* And we check again if the nulls are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ced28c6-2770-4acf-a7b8-334a9968a0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-------------+------------------+---------------------+\n",
      "|average_rating|num_pages|ratings_count|language_codeIndex|publication_yearIndex|\n",
      "+--------------+---------+-------------+------------------+---------------------+\n",
      "|             0|        0|            0|                 0|                    0|\n",
      "+--------------+---------+-------------+------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df3.na.drop()\n",
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "df3.select([count(when(isnull(c), c)).alias(c) for c in df3.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18ab882-188c-416d-8075-2313a9caf3b2",
   "metadata": {},
   "source": [
    "* Next we create our column features with vector assembler\n",
    "* We print the shema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6999b47-2529-46f6-941c-f0f76851854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- average_rating: double (nullable = true)\n",
      " |-- num_pages: integer (nullable = true)\n",
      " |-- ratings_count: integer (nullable = true)\n",
      " |-- language_codeIndex: double (nullable = false)\n",
      " |-- publication_yearIndex: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "inputCols=['num_pages',\n",
    " 'ratings_count',\n",
    " 'language_codeIndex',\n",
    " 'publication_yearIndex'],\n",
    "outputCol=\"features\")\n",
    "output = assembler.transform(df3)\n",
    "output.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45f9bc-ca12-4d63-9e00-7d356adf2ff9",
   "metadata": {},
   "source": [
    "* We select the two columns for regression alalysis\n",
    "* we print the shema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "122af8e2-0357-4c74-82c8-b2b697eac7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- average_rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select(\"features\",\"average_rating\")\n",
    "final_data = output.select(\"features\",\"average_rating\")\n",
    "final_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed34f62-0472-45ef-9552-52bbc7a405e0",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"question2\"></a> \n",
    "</b>\n",
    "<b> <span style=\"font-size: 200%\"> <span style='font-family:Helvetica'>Task 2 \"Preparing the training and testing datasets\"</b> \n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df54120-231d-4cb6-bcab-02ea84a3f317",
   "metadata": {},
   "source": [
    "* We split our data to train and test with 70% and 30% of total data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47b36d8b-2391-467f-bac9-aed9b13f64d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = final_data.randomSplit([0.7,0.3], seed =42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599a635-1edc-4a3c-bde5-9a51254e1a5c",
   "metadata": {},
   "source": [
    "* Finally, we call the linear regression package we imported with the two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fde9d182-ff9c-441e-94b7-2dc882aa674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =LinearRegression(featuresCol='features',labelCol='average_rating', regParam=1.0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85081fd-ae24-4bd9-aece-9bd28bb9d529",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"question3\"></a> \n",
    "</b>\n",
    "<b> <span style=\"font-size: 200%\"> <span style='font-family:Helvetica'>Task 3 \"Training the model\"</b> \n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc16f8db-0ffd-45e3-902d-12c26db650b3",
   "metadata": {},
   "source": [
    "* We proceed by training our model and printing the coefficients and interecept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d8bd3c7-f5d3-4403-a52a-cca413e3cd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.00023537229167000466,7.084859811602435e-07,0.001715765983396137,0.0006774048088672396]\n",
      "Intercept: 3.8749788154680296\n"
     ]
    }
   ],
   "source": [
    "lr_model = lr.fit(train_data)\n",
    "print(\"Coefficients: {}\".format(lr_model.coefficients))\n",
    "print(\"Intercept: {}\".format(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a985a7b-1257-4036-ab86-4ac0b797b51d",
   "metadata": {},
   "source": [
    "* Next we summarize the model over the training set and print out some metrics (RMSE, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "908b62e2-03ac-4bb6-9e25-b94932605883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4281650560028555\n",
      "r2: 0.023422959229442708\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: {}\".format(trainingSummary.rootMeanSquaredError))\n",
    "print(\"r2: {}\".format(trainingSummary.r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f28ba8c-7114-4597-a9b2-c5362beed544",
   "metadata": {},
   "source": [
    "* Next we proceed with testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0036a60-e6d7-4d02-80da-35e3bd18cbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+--------------------+\n",
      "|        prediction|average_rating|            features|\n",
      "+------------------+--------------+--------------------+\n",
      "| 3.880706165072637|          3.49| [14.0,55.0,1.0,1.0]|\n",
      "|3.9112205916226452|          4.17|[20.0,18.0,1.0,44.0]|\n",
      "|3.8845937268793334|          4.28| [22.0,16.0,1.0,4.0]|\n",
      "| 3.888205495925622|           4.0|  [23.0,1.0,1.0,9.0]|\n",
      "| 3.885548304652759|          4.65| [23.0,75.0,1.0,5.0]|\n",
      "+------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_predictions = lr_model.transform(test_data)\n",
    "lr_predictions.select(\"prediction\",\"average_rating\",\"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b221c99-bff1-41ef-82ba-dba21ec74ed5",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"question4\"></a> \n",
    "</b>\n",
    "<b> <span style=\"font-size: 200%\"> <span style='font-family:Helvetica'>Task 4 \"Evaluating the accuracy of the model\"</b> \n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afefd79a-d019-410a-aabc-28a9f0d08a2f",
   "metadata": {},
   "source": [
    "* Next we calculate the r2 on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0522a10-d36f-4f5c-8093-5836532e7ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.014475935934410322\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"average_rating\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = {}\".format(lr_evaluator.evaluate(lr_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44317e3d-bbfc-427e-b90e-2064ccc1506a",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"question5\"></a> \n",
    "</b>\n",
    "<b> <span style=\"font-size: 200%\"> <span style='font-family:Helvetica'>Task 5 \"Conclusions for all Spark Projects\"</b> \n",
    "> <img src=\"https://i.pinimg.com/originals/bb/37/72/bb3772f42dafd107b673974f80534e6c.gif\" alt=\"Drawing\" style=\"width: 396px;\"/> <br />\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7e03dc-2584-4591-8852-d7371fe4188f",
   "metadata": {},
   "source": [
    "* Implementing the tasks in Spark were a great chance to experiment with new open source, distributed computing framework and set of libraries.\n",
    "* Some benefits of using Spark is simplicity, scalability and compatibility (R, Python pandas, and scikit-learn)\n",
    "* The tasks were gradually getting harder, so they were well represented for someone with entry level knowledge\n",
    "* Also i learned deeper how to construct a well structured jupyter notebook\n",
    "* I riched my portofolio with spark projects that are in demand nowadays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6560c70-746c-49d2-b8c8-7aea3e5aa1a6",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "[Scroll To Top ^](#welcome) <img style=\"float: right;\" src=\"https://i.ibb.co/w7Lbd0X/2-AUEB-white-HR.jpg\"  alt=\"aueb\" width=\"550px\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a7227-3f75-4d73-b79b-f80da5f4f930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5745e4c-bfc4-4124-baac-19c6fd7338f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
